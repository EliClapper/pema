---
title       : "Selecting relevant moderators with Bayesian regularized meta-regression"
authors     : "masked"
journal     : "Research Synthesis Methods"
editor      : "Pigott"
manuscript  : "RSM-04-2022-0056"
class       : "draft"
bibliography      : ["r-references.bib", "references.bib",
                     "sara-references.bib", "eli-references.bib"]
output      : papaja::revision_letter_pdf
---

```{r, message=FALSE, warning=FALSE}
library(revise)
read_manuscript("manuscript.Rmd")
```

Dear Dr. `r rmarkdown::metadata$editor`,

Thank you for considering our manuscript for publication in _`r rmarkdown::metadata$journal`_.
We appreciate the thorough and critical comments you solicited,
which helped strengthen the argumentation, clarify the structure, and add nuance.
We have attempted to address all comments as thoroughly as possible.
All changes are explained below.
We hope that you will find the quality of the work to be sufficiently improved.

Yours sincerely,

the authors

# Associate Editor {-}

\RC{The authors introduce their implementation of a regularisation approach for estimation and variable selection in meta-regression, which seems a timely contribution given the danger of overfitting. Some more detail or elaboration would be helpful in some places.}

\RC{please consider whether the title is appropriate, or whether (something like) "Selecting..." or "Selection of..." might be better.}

We appreciate the suggestion and have changed the title to:

*Selecting relevant moderators with Bayesian regularized meta-regression*

\RC{in abstract and Introduction, please consider being more concrete here: it might be good to mention here already that this is about penalisation/LASSO/horseshoe priors in order to give the reader a better idea.}

We appreciate the suggestion and have made the requested change. The Abstract now reads:

`r get_revision("lassoabstract")`

In the Introduction, we now write:

REF

\RC{on p.16 (Section "design factors"):
what were the total numbers of variables (or "noise moderators")?}

We see now that we did not report clearly enough how many design factors there were and what they were.
Apparently, it was also not sufficiently clear that "noise moderators" are not the same as "design factors".
To address this comment and avoid confusion, we have rewritten this paragraph as follows:

`r get_revision("designfactors")`

\RC{regarding the 3rd comment by Reviewer 1: in the context of variable selection, the so-called "penalized complexity priors" (here: exponential priors for the heterogeneity standard deviation) might play a role.}

REF

# Reviewer 1

\RC{The manuscript provides an interesting approach based on regularization to selection of covariates in meta-regression, when the number of covariates is relevant. The Authors focus on a Bayesian strategy.
Although I found the topic interesting, the study needs some additional investigations and the text needs to be substantially modified in order to provide a clear and exhaustive picture of the proposal.
My comments and questions are listed below.}

We thank the Reviewer for their constructive comments, which substantially helped improve the quality of the manuscript.
We have tried to address them all in turn, as detailed below.

\RC{The introduction is too long in terms of explanation of the meta-regression and selection of covariates problems, with many repetitions. For example, end of page 4 and beginning of page 5 include many repetitions about between-study heterogeneity. Other parts, instead, require a substantially deeper explanation.}



\RC{Which theories useful for variable selection do you refer to in page 5 ? The description is extremely vague.}

\RC{The topic of the study is variable selection from a Bayesian point of view: but the description is so short. Just a few lines about the novelty of the paper in page 6, with no clear description of the proposal and with the reference to pema package without even the explanation of the name of the package.}

\RC{Statistical underpinnings: Again, I found a lot of repetitions in the text.}

\RC{Probably, in (1) you mean $\theta$ and not $\Theta$? As you have $\theta$ int the text. Why do you use theta and not beta, as you do for the meta-regression model in (7)? The notation would be simplified and would be more consistent.}

\RC{The sentence in lines 132-133 is not clear.}

\RC{line 147: probably the explanation of the error term should be anticipated where the error term appears for the first time.}

\RC{line 152: “to estimate this model “ has a preferable statistical sound than “to solve this model”}

\RC{lines 163- 166 describe some features of regularization….but regularization is introduced later, from line 167.}

\RC{Regularized regression + Bayesian estimation
I found both the sections very short and lacking of many details.}

\RC{what about the existing literature using lasso for meta-regression?}

\RC{In addition, I expected some references about the theory of LASSO given the relevance of the instrument in the literature.}

\RC{line 183-184: “other penalties exist”: ok, so discuss about, indicate advantages and disadvantages of the other solutions; why do you not focus on them in the study? If you do not, just explain why.}

\RC{Bayesian estimation: I think that some additional methodological details and additional explanations about priors and their comparison to the classical LASSO would help the reader.}

\RC{Why details relevant for the Bayesian estimation are included in the “Implementation” section? I mean lasso prior and horseshoe prior, that is, details useful to understand the methodology.}

\RC{Can you comment about the choice of the numerical values in the priors at the end of page 11?}

\RC{line 221: “this extension”: which one?}

\RC{line 225: “This is accomplished by..” Why?}

\RC{line 240: “values are reasonable in most applications” Why? Can you prove this?}

\RC{lines 244-251 seems to be pertinent to the methodology of the proposal not to implementation.}

\RC{More in general, I do not like to see a mixture of methodology and R code. I think I would be more useful for  the reader to have sections describing the proposed approach and the underlying methodology (something that is not present at the emano) and then having an appendix about the code. }

\RC{line 278: “x==0” could be substituted by “x is equal to 0” as this is a text, not a source code.}

We have made the suggested change.

\RC{Intercept.
I don’t think it is so relevant to deserve a section. Why not inserting a line in the section devoted to the code?}

\RC{Performance indicators, Design factors, Predictive performance
* You split the data in training set and test set, for each iteration. So, how do you account for the variability associated to the choice of the test set (as done for example in cross-validation)?}

\RC{I’m surprised by the large number fo linea devoted to the explanation of such a basic indicator like R2. In addition, it is well known to be optimistic, and thus the adjusted version I usually preferable. Why don’t you evaluate the method using other indicators, such as the adjusted r2, AIC, or BIC?}

\RC{line 344: I suppose you mean the estimate of sensitivity and specificity.}

\RC{line 368: 100 datasets only? Probably, there is a typo, as 100 is the number of datasets included in the test set, if I’m not wrong. In any case, 100 is a very low number of replicates for a simulation study, I suggest to increase at least to the common value equal to 1,000.}

\RC{line 385: do you mean “Table” 1?}

\RC{line 405: “the” most negative?}

\RC{lines 449-452 are not necessary as bias and variance are known concepts. However, in Tables I can see only bias, and not information about variance.}

\RC{lines 469-470: there is a white space}

\RC{Could you please avoid writing pema::bonapersona and use instead dataset titled bonapersona in the R pema package? This is not a list of lines code, but a text.}

\RC{you have 440 experiments in the dataset: do you mean 440 study included in the meta-regression? If so, the number is much. Larger than the scenarios evaluated in the simulations.}

\RC{Finally, There are many typos and inconsistencies throughout the text (e.g., data set and dataset, random effect and randoms-effects, …).}

# Reviewer 2

\RC{Comments to the Author
The authors investigated selection of moderators for the meta-regression, which is especially useful to explain the sources of heterogeneity between trials. They proposed the use of regularizing priors for meta-regression within a Bayesian framework. They shared publicly available R package "pema" which relies on rstan, which helps practitioners to use the proposed methods. I think the contribution of the paper and R package is important. However, I have some comments.}

## Major points

\RC{1) I think it is important to note some limitations of meta-regression. For example, the use of moderators might "break" the randomization, when the studies analyzed are randomized controlled trials. This is because it is not possible to randomize patients to one moderator, see Thompson and Higgins (2002) section 3 for further discussion of limitations of meta-regression of clinical trials.}

\RC{2) Important references are missing, in which the use of regularization or penalization approaches for the meta-analysis were investigated, although not the same purpose as in the current paper. For example, in Chung et al (2013) regularizing prior was used for the heterogeneity parameter to avoid boundary estimates, and in Günhan et al (2020) regularizing priors were used for the heterogeneity parameter and treatment effect parameter to deal with data sparsity. Finally and most importantly, Röver et al (2021) reviewed different use of regularizing priors and provided some guidance. Note that in the mentioned references, the term of weakly informative priors are used instead of regularizing priors (also see an earlier reference by Gelman (2006) in a hierarchical model context). Mention of these publications and relationship to the present paper can help the reader.}

We thank the Reviewer for suggesting these references, which had eluded our literature search.

We agree that the use of weakly informative priors for heterogeneity parameters was insufficiently discussed in the previous version of our manuscript, and have now added a paragraph on that topic (see our response to the next comment).

However, it is important to note that the use of weakly informative priors (WIP) for heterogeneity parameters serves a categorically different purpose than the use of regularizing priors for regression coefficients - even if the term "regularization" has been used for both in prior literature.
The purpose of WIP for heterogeneity parameters is to aid model convergence and avoid boundary estimates.
The purpose of regularizing priors for regression coefficients is to perform variable selection.
We believe that the newly added paragraph sufficiently clarifies these distinct uses of "regularization" (see response to next comment).

Thank you for pointing out these relevant references. We have included the reference to Chung et al. (2013), Gelman (2006) and Rover et al. (2021) in the new section on the prior for $\tau$ (see the next comment). In addition we have added the following section on page ... to be more explicit about the terminology of different types of priors:

Suggest to add this paragraph in the section on Bayesian estimation after "which reflects expectations about likely parameter values after having seen the data." Note: if included, this should be updated in the text from a previous comment to reviewer 1 as well. Also here it is relevant whether we use "regularizing" or "shrinkage" priors and should mention the definite choice explicitly.

"As a result, the posterior distribution is a compromise between the likelihood of the data and the prior distribution. The influence of either the data or the prior is determined by the sample size as well as the informativeness of the prior distribution. The larger the sample size, the more influential the likelihood of the data will be. Similarly, as the prior distribution becomes more informative, i.e., more peaked, it will exert more influence on the results. Priors can thus be placed on a continuum from "non-informative" to "highly informative". Weakly informative or regularizing priors are often used in situations when there is some prior information available, for example regarding the boundaries of the parameter space or, as is the case here, regarding the existence of parameters equal to zero. Throughout this manuscript, we will use the term "shrinkage prior" to refer to the weakly informative or regularizing prior that holds the prior knowledge that some coefficients are equal to zero and should therefore be shrunken towards zero."


\RC{3) An important part of Bayesian random-effects meta-analysis is the specification of the prior for the heterogeneity parameter tau. Can you include more specifications on the prior choice for tau and influence of the choice to the results (if there is any).}

We agree with the Reviewer that the prior specification for the heterogeneity parameter $tau$ is important and should be addressed in the text.
To address this comment, we have included the following paragraph in the revision:

`r get_revision("tauprior")`

Chung Y, Rabe-Hesketh S, Choi IH. Avoiding zero between-study variance estimates in random-effects meta-analysis. Stat Med. 2013;32(23):4071-4089.  

Gelman A. Prior distributions for variance parameters in hierarchical models. Bayesian Anal. 2006;1(3):515-534. [https://doi.org/10.1214/06-BA117A](https://doi.org/10.1214/06-BA117A "https://doi.org/10.1214/06-BA117A").

Gronau, Q. F., Van Erp, S., Heck, D. W., Cesario, J., Jonas, K. J., & Wagenmakers, E. J. (2017). A Bayesian model-averaged meta-analysis of the power pose effect with informed and default priors: The case of felt power. _Comprehensive Results in Social Psychology_, _2_(1), 123-138.

Röver, C, Bender, R, Dias, S, et al. On weakly informative prior distributions for the heterogeneity parameter in Bayesian random-effects meta-analysis. Res Syn Meth. 2021; 12: 448– 474. [https://doi.org/10.1002/jrsm.1475](https://doi.org/10.1002/jrsm.1475 "https://doi.org/10.1002/jrsm.1475")  

\RC{4) In the abstract and in the main text, it states "We present a simulation study to validate the performance of BRMA relative to state-of-the-art meta-regression (RMA)". What does RMA refer to here, is it "Random effect Meta-Analysis using REML"? If yes, I think the term random-effect meta-analysis (or meta-regression) using RMLE is more clear than state-of-the-art meta-analysis (or meta-regression).}

We have made the suggested correction. Both in the Abstract and in the text, the first time we introduce RMA, we introduce it as "random effects meta-analysis using restricted maximum likelihood".

## Minor points

\RC{Line 385: "see 1": I think Table is missing}

Thank you; we have corrected this.

# References
1) Thompson SG, Higgins JPT. How should meta-regression analyses be undertaken and interpreted?. Stat Med. 2002;21:1559-1573.
2) Chung Y, Rabe-Hesketh S, Choi IH. Avoiding zero between-study variance estimates in random-effects meta-analysis. Stat Med. 2013;32(23):4071-4089.
3) Günhan, BK, Röver, C, Friede, T. Random-effects meta-analysis of few studies involving rare events. Res Syn Meth. 2020; 11: 74– 90. https://doi.org/10.1002/jrsm.1370
4) Röver, C, Bender, R, Dias, S, et al. On weakly informative prior distributions for the heterogeneity parameter in Bayesian random-effects meta-analysis. Res Syn Meth. 2021; 12: 448– 474. https://doi.org/10.1002/jrsm.1475
5) Gelman A. Prior distributions for variance parameters in hierarchical models. Bayesian Anal. 2006;1(3):515-534. https://doi.org/10.1214/06-BA117A.



\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
